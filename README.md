# llm-tasker

> Package IAF pour ex√©cuter des t√¢ches avec des LLMs.

üëìüìò [Documentation](http://ia-factory.git-pages.intra.groupama.fr/datalab/iaf-packages/llm-tasker/nextrelease/) (√† r√©diger)

## Installation

Depuis le repo gitlab:

```bash
# via pip (ssh)
pip install git+git@git.ra1.intra.groupama.fr:ia-factory/datalab/iaf-packages/llm-tasker.git
```

Depuis pypi groupama:
_√† renseigner_

```bash
pip install llm-tasker
```

## Exemple d'usage

```python
from langchain_openai.chat_models import AzureChatOpenAI
from llmtasker.tasks.classification import Classification

# config LLM
llm = AzureChatOpenAI(...)

instructions = """
Tu es un classifier.

Tu dois identifier les animaux gr√¢ce √† la description. Donne un nom d'animal.

Voici les animaux possibles:
{classes}

# Exemples:
{examples}
"""

examples = {
    "Leur regard per√ßant semble contenir tous les secrets du monde.": "chat",
    "Leurs queues remuent de joie quand ils voient leur ma√Ætre rentrer √† la maison": "chien",
}

inputs = [
    "cr√©atures myst√©rieuses qui aiment se faufiler dans l'obscurit√©",
    "meilleurs amis de l'homme, toujours fid√®les et pleins d'amour.",
]

# cr√©ation de la t√¢che:
task = Classification(
    llm=llm,
    instructions=instructions,
    examples=examples,
    labels=Classification.build_labels_from_list(["chat", "chien", "autre"])
)

# Execution
outputs = task.run(inputs=inputs)

# Affichage des r√©sultats
for item in outputs:
    if item.error:
        print(item.error)
    if item.output:
        print(item.output)
    else:
        print(item.raw)

```


## Concepts

_√† d√©tailler avec le code associ√©_

Le package est construit autour de plusieurs concepts:

‚û°Ô∏è Le LLM: mod√®le de langue qui permet de traiter du texte de fa√ßon "intelligente".

‚û°Ô∏è Un prompt: Les insutrctions au LLMs qui corresponde √† la t√¢che souhait√©e. Le texte en entr√©e (input) est injecter dans le prompt. La gestion du prompt dans le package permet de g√©rer les diff√©rents r√¥les des exemples et de l'input.

‚û°Ô∏è Un executeur: c'est un suite logique d'op√©ration autour du LLM pour r√©aliser une t√¢che. Un executeur simple consiste √† enchaine un prompt, un llm et un parser.

‚û°Ô∏è Un item: concept qui repr√©sente une entr√©e (input) et une sortie (output). L'output repr√©sente le r√©sultat de l'executeur. L'item comporte aussi le r√©sultat du llm (raw) et les √©ventuelles erreurs durant l'execution (error). L'item permet de g√©rer la fa√ßon dont il s'affiche dans le prompt comme exemple ou input.

‚û°Ô∏è Une t√¢che: elle correspond √† une action m√©tier sur du texte (r√©sum√©, classification, personnalis√©e...).


## T√¢ches

_√† d√©tailler avec les noms des classes_

Les t√¢ches sont repr√©sent√©es par des classes pr√™tes √† l'emploi. Par exemple: `from llmtasker.task.classification import Classification`.

- ‚úÖ Classification (input: text, output: un label)

    * Ouverte / Ferm√©e
    * Mono / Multi labels
    * Group√©e (plusieurs inputs en un message)

- ‚úÖ Instruction personnalis√©e (input: text, output: un dictionnaire ou un objet pydantic)

    * mode json
    * function calling


## Fonctionnalit√©s

- ‚û°Ô∏è impl√©mentation langchain
    - ‚òëÔ∏è retry de l'appel llm
    - ‚òëÔ∏è gestion des erreurs (error)
    - ‚òëÔ∏è recup√©ration du r√©sultat du llm (raw)
    - ‚òëÔ∏è parser pydantic/json/classe (output)
    - ‚òëÔ∏è gestion du prompt:
      - ‚òëÔ∏è gestion des variables
      - ‚òëÔ∏è gestion des exemples
      - ‚òëÔ∏è gestion des classes
      - ‚òëÔ∏è choix du r√¥le pour les examples et l'input
    - ‚òëÔ∏è grouper les inputs en un message au llm
- ‚òëÔ∏è Interface visuel pour la classification
- ‚òëÔ∏è Gitlab-ci (tests, formatter, docs, version, release)
- ‚òëÔ∏è API classification
- ‚òëÔ∏è API instruction personnalis√©e


## Dev du package

### Abstraction

Gestion de la structure de base du package (classes abstraites et interfaces) sans prendre en compte une impl√©mentation particuli√®re. Pas forc√©ment beaucoup de code. Possibilit√© d'impl√©menter avec un client diff√©rent de langchain par exemple.


### Impl√©mentation langchain des t√¢ches

D√©finie une t√¢che sp√©cifique pour un usage sp√©cifique. Censer √™tre simple √† utiliser.

### Impl√©mentation avanc√©e avec langchain

Coeur du package. Permet beaucoup de flexibilit√© mais n'est pas simple pour l'utilisateur.


## Contribuer

Pr√©requis:
* installer `poetry`

Puis,
1. Clone le code
2. (optionnel) Cr√©er un environnement virtuel
3. Installer les d√©pendances de dev: `poetry install --with dev`
4. Installer les precommits: `pre-commit install`

Si besoin d'ajouter un package de dev: `poetry add <nom_package> --group dev`

Sinon: `poetry add <nom_package>`

Nous utilisons les grandes lignes du [gitlab flow](https://docs.gitlab.com/ee/topics/gitlab_flow.html):

* une branche `main` qui suit les √©volutions
* des branches de features (`feature/ma-feat`)
* des branches de release pour mettre √† jour seulements les infos de release et le tag `release/vX.X.X`
  * Elle doit √™tre d'une dur√©e de vie courte
  * Si des bugfix doivent √™tre ajout√©s, c'est possible dans la branche de release
* des tags prot√©g√©s sous la forme `vX.X.X` qui d√©clencheront une release sur le pypi interne + documentation


## TODO

* Documenter les t√¢ches
* D√©velopper les tests unitaires des items
* D√©velopper les tests unitaires des t√¢ches
* Factoriser + le code API
* Ajouter un exemple de t√¢che classification ouverte
* Ajouter des prompts g√©n√©riques dans `prompts/`
* D√©tailler la documentation g√©n√©rer par mkdocs
* D√©velopper la fonction run() des t√¢ches en asynchrone
* Ajouter callback langfuse en exemple + API
* Etudier et utiliser [json_repair](https://github.com/mangiucugna/json_repair)
